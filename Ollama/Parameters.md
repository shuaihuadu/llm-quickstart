| 参数名称          | 中文翻译                                                                                                                          | 英文解释                                                                                                                                                                                                                         |
| ----------------- | --------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| mirostat          | 启用Mirostat采样以控制困惑度。（默认值：0，0=禁用，1=Mirostat，2=Mirostat 2.0）                                                   | Enable Mirostat sampling for controlling perplexity. (default: 0, 0 = disabled, 1 = Mirostat, 2 = Mirostat 2.0)                                                                                                                  |
| mirostat_eta      | 影响算法响应生成文本反馈的速度。较低的学习率会导致调整较慢，而较高的学习率会使算法更敏感。（默认值：0.1）                         | Influences how quickly the algorithm responds to feedback from the generated text. A lower learning rate will result in slower adjustments, while a higher learning rate will make the algorithm more responsive. (Default: 0.1) |
| mirostat_tau      | 控制输出的连贯性与多样性的平衡。较低的值会生成更集中和连贯的文本。（默认值：5.0）                                                 | Controls the balance between coherence and diversity of the output. A lower value will result in more focused and coherent text. (Default: 5.0)                                                                                  |
| num_ctx           | 设置用于生成下一个标记的上下文窗口大小。（默认值：2048）                                                                          | Sets the size of the context window used to generate the next token. (Default: 2048)                                                                                                                                             |
| repeat_last_n     | 设置模型回溯以防止重复的范围。（默认值：64，0=禁用，-1=num_ctx）                                                                  | Sets how far back for the model to look back to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)                                                                                                                    |
| repeat_penalty    | 设置重复惩罚的强度。较高的值（例如1.5）会更强烈地惩罚重复，而较低的值（例如0.9）则会更宽容。（默认值：1.1）                       | Sets how strongly to penalize repetitions. A higher value (e.g., 1.5) will penalize repetitions more strongly, while a lower value (e.g., 0.9) will be more lenient. (Default: 1.1)                                              |
| temperature       | 模型的温度。提高温度会使模型的回答更有创意。（默认值：0.8）                                                                       | The temperature of the model. Increasing the temperature will make the model answer more creatively. (Default: 0.8)                                                                                                              |
| seed              | 设置用于生成的随机数种子。将其设置为特定数字会使模型对相同的提示生成相同的文本。（默认值：0）                                     | Sets the random number seed to use for generation. Setting this to a specific number will make the model generate the same text for the same prompt. (Default: 0)                                                                |
| stop              | 设置停止生成文本的序列。当遇到该模式时，LLM将停止生成文本并返回。可以通过在模型文件中指定多个单独的`stop`参数来设置多个停止模式。 | Sets the stop sequences to use. When this pattern is encountered the LLM will stop generating text and return. Multiple stop patterns may be set by specifying multiple separate `stop` parameters in a modelfile.               |
| tfs_z             | 尾部自由采样用于减少低概率标记对输出的影响。较高的值（例如2.0）会更多地减少影响，而1.0的值则禁用该设置。（默认值：1）             | Tail free sampling is used to reduce the impact of less probable tokens from the output. A higher value (e.g., 2.0) will reduce the impact more, while a value of 1.0 disables this setting. (default: 1)                        |
| num_predict       | 生成文本时预测的最大标记数。（默认值：128，-1=无限生成，-2=填充上下文）                                                           | Maximum number of tokens to predict when generating text. (Default: 128, -1 = infinite generation, -2 = fill context)                                                                                                            |
| top_k             | 减少生成无意义文本的概率。较高的值（例如100）会给出更多样化的回答，而较低的值（例如10）则会更保守。（默认值：40）                 | Reduces the probability of generating nonsense. A higher value (e.g. 100) will give more diverse answers, while a lower value (e.g. 10) will be more conservative. (Default: 40)                                                 |
| top_p             | 与top-k一起工作。较高的值（例如0.95）会生成更多样化的文本，而较低的值（例如0.5）则会生成更集中的保守文本。（默认值：0.9）         | Works together with top-k. A higher value (e.g., 0.95) will lead to more diverse text, while a lower value (e.g., 0.5) will generate more focused and conservative text. (Default: 0.9)                                          |
| mirostat          | 微状态调节参数，控制生成文本的动态调整机制。                                                                                      | A parameter for dynamic adjustment mechanism in text generation.                                                                                                                                                                 |
| mirostat_eta      | 微状态的步长参数，控制模型微调步长的大小。                                                                                        | Step size parameter for mirostat, controlling the adjustment step size.                                                                                                                                                          |
| mirostat_tau      | 微状态的目标熵参数，控制生成文本的熵值。                                                                                          | Target entropy parameter for mirostat, controlling the entropy of generated text.                                                                                                                                                |
| num_ctx           | 上下文窗口大小，决定模型在一次推理中能考虑的上下文长度。                                                                          | Context window size, determining the length of context the model can consider in one inference.                                                                                                                                  |
| repeat_last_n     | 重复检测窗口大小，用于检测生成文本中的重复片段。                                                                                  | Repeat detection window size, used to detect repeated segments in generated text.                                                                                                                                                |
| repeat_penalty    | 重复惩罚系数，控制对重复文本的惩罚力度。                                                                                          | Repeat penalty coefficient, controlling the penalty strength for repeated text.                                                                                                                                                  |
| temperature       | 温度参数，控制生成文本的随机性。                                                                                                  | Temperature parameter, controlling the randomness of generated text.                                                                                                                                                             |
| seed              | 随机种子，用于结果的可重复性。                                                                                                    | Random seed, used for reproducibility of results.                                                                                                                                                                                |
| stop              | 停止词列表，遇到这些词时生成文本会停止。                                                                                          | List of stop words, generation stops when these words are encountered.                                                                                                                                                           |
| tfs_z             | 指定一种采样方法，结合top-k和top-p的优势。                                                                                        | Specifies a sampling method that combines the advantages of top-k and top-p.                                                                                                                                                     |
| num_predict       | 预测的token数量，控制生成文本的长度。                                                                                             | Number of tokens to predict, controlling the length of generated text.                                                                                                                                                           |
| top_k             | 最高概率选取的候选词数，控制生成文本的多样性。                                                                                    | Number of top probable words to consider, controlling the diversity of generated text.                                                                                                                                           |
| top_p             | 累积概率截断值，控制生成文本的多样性。                                                                                            | Cumulative probability cutoff, controlling the diversity of generated text.                                                                                                                                                      |
| num_keep          | 保持的token数量，用于生成长文本时的上下文保留。                                                                                   | Number of tokens to keep, used for context retention in long text generation.                                                                                                                                                    |
| typical_p         | 典型性采样参数，控制生成文本的典型性。                                                                                            | Typicality sampling parameter, controlling the typicality of generated text.                                                                                                                                                     |
| presence_penalty  | 出现惩罚系数，控制生成文本中词语重复出现的惩罚力度。                                                                              | Presence penalty coefficient, controlling the penalty for the repeated occurrence of words in the generated text.                                                                                                                |
| frequency_penalty | 频率惩罚系数，控制生成文本中词语频率的惩罚力度。                                                                                  | Frequency penalty coefficient, controlling the penalty for the frequency of words in the generated text.                                                                                                                         |
| penalize_newline  | 换行惩罚参数，控制生成文本中换行符的使用频率。                                                                                    | Newline penalty parameter, controlling the frequency of newline characters in the generated text.                                                                                                                                |
| numa              | NUMA（非统一内存访问）节点配置。这个参数用于指定模型运行时使用的NUMA节点，优化内存访问性能。                                      | NUMA (Non-Uniform Memory Access) node configuration. This parameter is used to specify the NUMA nodes utilized during model execution to optimize memory access performance.                                                     |
| num_batch         | 批处理大小，控制每次推理的输入数量。                                                                                              | Batch size, controlling the number of inputs per inference.                                                                                                                                                                      |
| num_gpu           | 使用的GPU数量，控制模型推理时的硬件资源分配。                                                                                     | Number of GPUs used, controlling hardware resource allocation for model inference.                                                                                                                                               |
| main_gpu          | 主GPU编号，指定主要使用的GPU。                                                                                                    | Main GPU ID, specifying the primary GPU to use.                                                                                                                                                                                  |
| low_vram          | 低显存模式，优化模型在显存较低的环境下运行。                                                                                      | Low VRAM mode, optimizing the model to run in environments with limited GPU memory.                                                                                                                                              |
| f16_kv            | 使用半精度浮点数表示键值对，提高计算效率。                                                                                        | Use half-precision floating-point for key-value pairs, improving computational efficiency.                                                                                                                                       |
| vocab_only        | 仅使用词汇表模式，控制模型只生成词汇表中的词语。                                                                                  | Vocabulary-only mode, controlling the model to generate only words from the vocabulary.                                                                                                                                          |
| use_mmap          | 使用内存映射技术，提高大模型在磁盘上的读写效率。                                                                                  | Use memory-mapped file technique, improving read/write efficiency for large models on disk.                                                                                                                                      |
| use_mlock         | 使用内存锁定技术，防止内存分页，确保计算性能。                                                                                    | Use memory locking technique, preventing memory paging to ensure computational performance.                                                                                                                                      |
| num_thread        | 使用的线程数量，控制模型推理时的并行计算能力。                                                                                    | Number of threads used, controlling parallel computation capability during model inference.                                                                                                                                      |